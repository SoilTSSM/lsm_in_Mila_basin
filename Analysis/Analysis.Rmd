---
title: "Landslide susceptibility mapping in Mila basin"
author: "Merghadi Abdelaziz"
date: "01/09/2017"
output: html_document
---

```{r Setup, message=FALSE, warning=FALSE, include=FALSE}
## Setup Knitr options :
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(echo = TRUE,cache = TRUE,fig.width = 7,fig.height = 7,dpi = 1200,cache.rebuild = F)

## Assure That English is Sys. Language
Sys.setenv(LANG = "en_US.UTF-8")
Sys.setlocale(category = "LC_ALL",locale = "en_US.UTF-8")
options(papersize = "special")

## Loading Required Libraries 
library(setRNG,quietly = T)
library(ggplot2,quietly = T)
library(dplyr,quietly = T)
library(mlr,quietly = T)
library(mlrMBO,quietly = T)
#library(parallelMap,quietly = T)

## Init. Project Folder Path 
PROJHOME = normalizePath(rprojroot::find_rstudio_root_file())

## Load required Script/Function files
source(file.path(PROJHOME, "R", "Checking_And_Ploting_NA.R"))
source(file.path(PROJHOME, "R", "Correlation_Correlogram_Func.R"))
source(file.path(PROJHOME, "R", "Variance_Inflation_Factor_Func.R"))
source(file.path(PROJHOME, "R", "Hyperparmeter_Ploting_Func.R"))
source(file.path(PROJHOME, "R", "Roc_Ploting_Func.R"))

## Init. Necessary Folders
## Checking the existence of certain folders if not create them
ifelse(!dir.exists(file.path(PROJHOME,"Data")),dir.create(file.path(PROJHOME,"Data")),F)

ifelse(!dir.exists(file.path(PROJHOME,"Outputs")),dir.create(file.path(PROJHOME,"Outputs")),F)

ifelse(!dir.exists(file.path(PROJHOME,"Outputs","Tables")),dir.create(file.path(PROJHOME,"Outputs","Tables")),F)

ifelse(!dir.exists(file.path(PROJHOME,"Outputs","Figures")),dir.create(file.path(PROJHOME,"Outputs","Figures")), F)

## Configure Mlr Package
mlr::configureMlr(show.info = F, show.learner.output = F,on.learner.warning = "quiet")

  
```

the control object for the optimization is based on the Return of the best point ever visited according to true value of target function using Expected Improvement as infill criterion that guides the model based search process both with kriging as surrogate model since we are solving a numeric problem & 20 iteration of evaluations plus additional 3 evaluations at the end.
a part from 23 evaultions mentioned above there exist 4 by (number.of.paramters) initial evaluation marked as the enitial design search except learners that have dummyfied wrapper we implement a custum design of 5*(number.of.paramters) due to the introduction of additional variables.

```{r Init. Data & Resampling Discriptions, echo=TRUE}

  ## Number of CPUs to use in Optimization
  cpus = 2L
  
  ## seed for resampling stratigies
  setRNG::setRNG("L'Ecuyer",101)

  ## Load Input Data
  Samples <- read.csv(file.path(PROJHOME, "Data", "Input_Dataset.csv"),header = T)
  #Samples <- read.csv(file.path(PROJHOME, "res555.csv"),header = T)

  ## Load data as task with "Yes" as Positive Class to target ##
  Benchmark_Task <- makeClassifTask(id= "Benchmark",data =Samples,target = "Landslides", positive = "Yes" ,fixup.data = "quiet")

  ## Setup the desired resampling Stratigy With 10 CV as Nested Inner Sampling ##
  Rdesc_Outer = makeResampleInstance(desc = makeResampleDesc(method = "Holdout",
                                                             stratify = T,predict = "both",split=0.70),task = Benchmark_Task)
  Rdesc_Inner = makeResampleDesc(method = "CV",stratify = F,predict = "both",iters=10L)

  ## Subset The Main Task Based on Outer Resampling & dummyfing in case leaner Support Only Numeric Inputs
  Tuning_Task <- mlr::subsetTask(Benchmark_Task,subset = Rdesc_Outer$train.inds[[1]])

  ## Init. The Inner Objective function For The Experiment
  # NOTE: set seed to Ecuyer since we parallelise the experiment
  lrn.fun <- function(cl,id,par.vals,task,resampling,objectives,dummy,preproc,aggr,seed) {
    
    ## Argument Flags
    #assertChoice(cl, choices = mlr::listLearners()$class)
    #cl.flag = is.null(cl) || !(cl %in% mlr::listLearners()$class)
    checkmate::assertFlag(dummy)
    checkmate::assertFlag(preproc)
    checkmate::assertFlag(aggr)
    
    ## Init. The Stopping critireon 
    # if (cl.flag)
    #   stopf("Unsupported Learner")
    if (is.null(seed) || length(objectives) > 24 ) 
      stopf("Set seed or greater than 24 objective is not supported yet")
    
    ## setup Function Structure
    
    if (dummy) {
      setRNG::setRNG("L'Ecuyer",seed)
      lrn = mlr::makeDummyFeaturesWrapper(mlr::makeLearner(cl,predict.type = "prob",id = id, par.vals = par.vals))
    }
    else {
      setRNG::setRNG("L'Ecuyer",seed)
      lrn = mlr::makeLearner(cl,predict.type = "prob",id = id, par.vals = par.vals)
    } 
    
    if (preproc) {
      lrn = mlr::makePreprocWrapperCaret(lrn,ppc.center=T,ppc.scale=T,ppc.range=F)
    }
    else {
      lrn = lrn
    }  
    
    if (aggr){ 
      res = mlr::resample(lrn, task,resampling, measures = objectives,models = T, show.info = F)$aggr
    }
    else {
      res = mlr::resample(lrn, task,resampling, measures = objectives,models = T, show.info = F)
    }
    
    # return Outcomes
    return(res)
    
  }
  
  Measures <- list(logloss,acc,kappa,auc,setAggregation(logloss,train.mean),setAggregation(acc,train.mean),setAggregation(kappa,train.mean),setAggregation(auc,train.mean))
  ## Init. Baysian Optimization Search Control
  # construct the Model Based Optimization control object 
  ctrl = makeMBOControl()
  
  # We will allow for 30 iteration after the initial design of the objective function:
  ctrl = setMBOControlTermination(ctrl,iters = 30L)
  #ctrl = setMBOControlMultiPoint(ctrl,method = "cb")

  ## set Infill criteria to Optimize Confidence bound with variable lamdba based On The parameters Spaces to optimize 
  ctrl = setMBOControlInfill(ctrl, crit = crit.cb)
  ## set Infill criteria based On The parameters Spaces to optimize 


```


```{r Checking & Ploting NA Values, echo=TRUE,dpi=1200,fig.align="center"}

  ## Missing Data Plot 
  Missing_Values_Plot <- Na_Plot(Input.Data = Samples)
  ggsave(file.path(PROJHOME, "Outputs","Figures","Missing_Values_Plot.eps"),plot = Missing_Values_Plot,width = 5,height = 5,dpi = 1200 ,device = "eps",units = "in")
  
  ## Correlogram for The Input Data
  #grDevices::postscript(file = "Plots/Correlogram_Plot.eps",width =5 ,height = 5,horizontal = FALSE,onefile = FALSE, paper = "special")
  Correlogram=Cor_Ggplot(Samples)
  ggsave(file.path(PROJHOME, "Outputs","Figures","Correlogram.eps"),plot = Correlogram,width = 5,height = 5,dpi = 1200 ,device = "eps",units = "in")
  
 ## Vif for The Input Data
  Vif <- Vif_Plot(Input.Data = Samples,form = Landslides ~ .,lim = c(0,5.2),"Variance Inflation Factor","")
  ggsave(file.path(PROJHOME, "Outputs","Figures","Vif_Plot.eps"),plot = Vif,width = 5,height = 5,dpi = 1200 ,device = "eps",units = "in")    

```

 the Gradient Boosting Machine (GBM) using : Generalized Boosted Regression Models (gbm) Package.
 
```{r Tune & Benchmark GBM, echo=TRUE, message=FALSE, warning=FALSE}

  ## Set Seed
  setRNG::setRNG("L'Ecuyer",101)
  
  ## Init Hyperparamter set to be tuned
  gbm.ps <- makeParamSet(#makeDiscreteParam("distribution",values = "bernoulli" ),
                         makeNumericParam("shrinkage",0,1 ),
                         makeNumericParam("bag.fraction",0.5,1 ),
                         #makeNumericParam("train.fraction",0.1,1 ),
                         makeIntegerParam("n.trees",32L,2048L) ,
                         makeIntegerParam("interaction.depth",1L,8L )
                         #makeIntegerParam("n.minobsinnode",lower = 10L,upper = 30L )
                         )

  ## Init. Objective Functions
  gbm = smoof::makeSingleObjectiveFunction(name = "gbm.tuning",
                                          fn = function(x) {lrn.fun(cl = "classif.gbm",id = "GBM",par.vals = x,task = Tuning_Task,resampling = Rdesc_Inner,objectives = list(logloss),dummy=F,preproc=F,aggr=T,seed = 101)},
                                          par.set = gbm.ps,has.simple.signature = FALSE,noisy = F,minimize = T)
  
  ## init design space for the optimization 
  gbm.des = ParamHelpers::generateDesign(40L, getParamSet(gbm), fun = lhs::optimumLHS)

  # Tune gbm
  tune.gbm = mlrMBO::mbo(gbm, gbm.des, control = ctrl, show.info = TRUE)

  ## Extract The Best all Possible HyperCombination for The optimization
  gbm.set <- tune.gbm$x
  write.csv(dplyr::bind_rows(gbm.set),file.path(PROJHOME, "Outputs","Tables","gbm.set.csv"), row.names=F)
  
  ## Extract All The Optimization Evaluations
  gbm.opt.path = as.data.frame(tune.gbm$opt.path,stringsAsFactors=F)
  
  ## Generate Hyperparamter effect Plots
  gbm.hyper.plots.1 = hyperplot(gbm.opt.path,"interaction.depth","shrinkage","y","regr.randomForest",
                                lab.x = "Variable interactions depth",lab.y ="Learning rate",
                                lab.z ="Area Under Curve" ,8,c(1,8),5,c(0,1),5)
  gbm.hyper.plots.3 = hyperplot(gbm.opt.path,"bag.fraction","shrinkage","y","regr.randomForest",
                                lab.x = "Subsampling fraction",lab.y ="Learning rate",
                                lab.z ="Logarithmic loss" ,5,c(0.5,1),5,c(0,1),5)
  gbm.hyper.plots.2 = hyperplot(gbm.opt.path,"n.trees","shrinkage","y","regr.randomForest",
                                lab.x = "Number of trees",lab.y ="Learning rate",
                                lab.z ="Logarithmic loss" ,8,c(32L,2048L),5,c(0,1),5)

    ## Export Hyperparamter effect Plots
    ggsave(file.path(PROJHOME, "Outputs","Figures",paste0("gbm_","interaction_depth","_vs_","shrinkage",".eps")),
           gbm.hyper.plots.1,"eps",width = 6,height = 6,units = "in",dpi = 1200)

    ggsave(file.path(PROJHOME, "Outputs","Figures",paste0("gbm_","bag_fraction","_vs_","shrinkage",".eps")),
           gbm.hyper.plots.3,"eps",width = 6,height = 6,units = "in",dpi = 1200)
    
       ggsave(file.path(PROJHOME, "Outputs","Figures",paste0("gbm_","n_trees","_vs_","shrinkage",".eps")),
           gbm.hyper.plots.2,"eps",width = 6,height = 6,units = "in",dpi = 1200) 

  # Benchmark gbm Using all HyperCombination supplied by tune.gbm
  setRNG::setRNG("L'Ecuyer",101)
  final.gbm.model <- lrn.fun(cl = "classif.gbm",id = "GBM",par.vals = gbm.set,task = Benchmark_Task,resampling = Rdesc_Outer,objectives = Measures,dummy=F,preproc=F,aggr=F,seed = 101)


```

Init the Random Forests (RF) using: A Fast Implementation of Random Forests (Ranger) Package.

```{r Tune & Benchmark RF, message=FALSE, warning=FALSE, include=FALSE}

  ## Set Seed
  setRNG::setRNG("L'Ecuyer",101)

  ## Init Hyperparamter set to be tuned
  rf.ps <- makeParamSet(##makeDiscreteParam("replace",values = c("FALSE"=FALSE)),
                        makeLogicalParam("replace"),
                        #makeDiscreteParam("respect.unordered.factors",values = c("TRUE"=TRUE)),
                        makeNumericParam("sample.fraction", 0.632, 1 ),
                        makeIntegerParam("num.trees", 64L , 1024L ),
                        makeIntegerParam("mtry",2L,8L ))
 
  ## Init. Objective Functions
  rf = smoof::makeSingleObjectiveFunction(name = "rf.tuning",
                                           fn = function(x) {lrn.fun(cl = "classif.ranger",id = "RF",par.vals = x,task = Tuning_Task,resampling = Rdesc_Inner,objectives = list(logloss),dummy=F,preproc=F,aggr=T,seed = 101)},
                                           par.set = rf.ps,has.simple.signature = FALSE,noisy = F,minimize = T)

  ## init design spwwace for the optimization 
  rf.des = ParamHelpers::generateDesign(40L, getParamSet(rf), fun = lhs::optimumLHS)
  
  # Tune rf
  tune.rf = mlrMBO::mbo(rf, rf.des, control = ctrl, show.info = TRUE)

  ## Extract The Best all Possible HyperCombination for The optimization
  rf.set <- tune.rf$x
  write.csv(dplyr::bind_rows(rf.set),file.path(PROJHOME, "Outputs","Tables","rf.set.csv"), row.names=F)
  
  ## Extract All The Optimization Evaluations
  rf.opt.path = as.data.frame(tune.rf$opt.path,stringsAsFactors=F)
  
  ## Generate Hyperparamter effect Plots
  rf.hyper.plots.1 = hyperplot(data = rf.opt.path,x = "mtry",y = "num.trees",z = "y","regr.randomForest",
                               lab.x = "Number of variables",lab.y ="Number of trees",
                               lab.z ="Logarithmic loss" ,7,c(2,8),8,c(64,1024),5)
  rf.hyper.plots.2 = hyperplot(data = rf.opt.path,x = "mtry",y = "sample.fraction",z = "y","regr.randomForest",
                               lab.x = "Number of variables",lab.y ="Sampling fraction",
                               lab.z ="Logarithmic loss" ,7,c(2,8),7,c(0.632,1),5)
  
  ## Export Hyperparamter effect Plots
  ggsave(file.path(PROJHOME, "Outputs","Figures",paste0("rf_","mtry","_vs_","num_trees",".eps")),
         rf.hyper.plots.1,"eps",width = 6,height = 6,units = "in",dpi = 1200)
  ggsave(file.path(PROJHOME, "Outputs","Figures",paste0("rf_","mtry","_vs_","sample_fraction",".eps")),
         rf.hyper.plots.2,"eps",width = 6,height = 6,units = "in",dpi = 1200)

  # Benchmark rf Using all HyperCombination supplied by tune.rf
  setRNG::setRNG("L'Ecuyer",101)
  final.rf.model <- lrn.fun(cl = "classif.ranger",id = "RF",par.vals = rf.set,task = Benchmark_Task,resampling = Rdesc_Outer,objectives = Measures,dummy=F,preproc=F,aggr=F,seed = 101)
  

```

Init the Multilayer Perceptron Neural Network (MLP) using: Feed-Forward Neural Networks and Multinomial Log-Linear Models (nnet)

```{r Tune & Benchmark nnet, message=FALSE, warning=FALSE, include=FALSE}

  ## Set Seed
  setRNG::setRNG("L'Ecuyer",101)

  ## Init Hyperparamter set to be tuned
  nnet.ps <- makeParamSet(#makeIntegerParam("maxit",2e+1L,2e+1L ),
                         makeDiscreteParam("MaxNWts",values = 1e+5L ),
                         #makeNumericParam("rang",0.25,025 ),
                         #makeDiscreteParam("Hess",list("FALSE" = FALSE)),
                         #makeDiscreteParam("trace",list("FALSE" = FALSE)),
                         makeIntegerParam("size",6L,54L ) ,
                         makeNumericParam("decay",0,1 ))
 
  ## Init. Objective Functions
  nnet = smoof::makeSingleObjectiveFunction(name = "nnet.tuning",
                                           fn = function(x) {lrn.fun("classif.nnet","NNET",par.vals =x,Tuning_Task,Rdesc_Inner,objectives = list(logloss),dummy=F,preproc=F,aggr=T,seed = 101)},
                                           par.set = nnet.ps,has.simple.signature = FALSE,noisy = F,minimize = T)
  
  ## init design space for the optimization 
  nnet.des = ParamHelpers::generateDesign(40L, getParamSet(nnet), fun = lhs::optimumLHS)
  
  # Tune nnet
  tune.nnet = mlrMBO::mbo(nnet, nnet.des, control = ctrl, show.info = TRUE)

  ## Extract The Best all Possible HyperCombination for The optimization
  nnet.set <- tune.nnet$x
  write.csv(dplyr::bind_rows(nnet.set),file.path(PROJHOME, "Outputs","Tables","nnet.set.csv"), row.names=F)
  
  ## Extract All The Optimization Evaluations
  nnet.opt.path = as.data.frame(tune.nnet$opt.path,stringsAsFactors=F)
  
  ## Generate Hyperparamter effect Plots
  nnet.hyper.plots = hyperplot(data = nnet.opt.path,x = "size",y = "decay",z = "y","regr.randomForest",
                              lab.x = "Number of hidden units",lab.y ="Weight decay",
                              lab.z ="Logarithmic loss" ,8,c(6,54),5,c(0,1),10)
  
  ## Export Hyperparamter effect Plots
  ggsave(file.path(PROJHOME, "Outputs","Figures",paste0("nnet_","size","_vs_","decay",".eps")),
         nnet.hyper.plots,"eps",width = 6,height = 6,units = "in",dpi = 1200)

  # Benchmark nnet Using all HyperCombination supplied by tune.nnet
  setRNG::setRNG("L'Ecuyer",101)
  final.nnet.model <- lrn.fun(cl = "classif.nnet",id = "NNET",par.vals = nnet.set,task = Benchmark_Task,resampling = Rdesc_Outer,objectives = Measures,dummy=F,preproc=F,aggr=F,seed = 101)

```

Init the Support Vector Machine (SVM) using : Misc Functions of the Department of Statistics,Probability Theory Group(Formerly:E1071) Package.

```{r Tune & Benchmark SVM, message=FALSE, warning=FALSE, include=FALSE}

  ## Set Seed
  setRNG::setRNG("L'Ecuyer",101)

  ## Init Hyperparamter set to be tuned rbfdot
  svm.ps <-  makeParamSet(makeDiscreteParam("kernel",values = "radial"),
                          makeNumericParam("cost",-15,15,trafo = function(x) 2^x),
                          makeNumericParam("gamma",-15,15,trafo = function(x) 2^x))

  ## Init. Objective Functions
  svm = smoof::makeSingleObjectiveFunction(name = "svm.tuning",
fn =function(x){lrn.fun("classif.svm","SVM",x,Tuning_Task,Rdesc_Inner,list(logloss),F,F,T,101)},
                                           par.set = svm.ps,has.simple.signature = FALSE,noisy = F,minimize = T)
  
  ## init design space for the optimization 
  svm.des = ParamHelpers::generateDesign(40L, getParamSet(svm), fun = lhs::optimumLHS)
  
  # Tune svm
  tune.svm = mlrMBO::mbo(svm, svm.des, control = ctrl, show.info = TRUE)

  ## Extract The Best all Possible HyperCombination for The optimization
  svm.set <- tune.svm$x
  trafo_set <- c("cost","gamma")
  for (i in trafo_set){svm.set[[i]] = 2^svm.set[[i]]}
  write.csv(dplyr::bind_rows(svm.set),file.path(PROJHOME, "Outputs","Tables","svm.set.csv"), row.names=F)
  
  ## Extract All The Optimization Evaluations
  svm.opt.path = as.data.frame(tune.svm$opt.path,stringsAsFactors=F)
  
  ## Generate Hyperparamter effect Plots
  ## Init. a modified axis scale that have custom transformation labels 
  scls<- list(scale_x_continuous(expand = c(0,0),limits = c(-15,15),breaks = scales::extended_breaks(n = 8),
                                 labels = scales::trans_format("identity", scales::math_format(2^.x))),
              scale_y_continuous(expand = c(0,0),limits = c(-15,15),breaks = scales::extended_breaks(n = 8),
                                 labels =scales::trans_format("identity", scales::math_format(2^.x))))

  svm.hyper.plots = hyperplot(data = svm.opt.path,x = "cost",y = "gamma",z = "y","regr.randomForest",
                lab.x = "Cost",lab.y ="Gamma",lab.z ="Logarithmic loss" ,6,c(-15,15),6,c(-15,15),7) + scls
  
  ## Export Hyperparamter effect Plots
    ggsave(file.path(PROJHOME, "Outputs","Figures",paste0("svm_","cost","_vs_","gamma",".eps")),
           svm.hyper.plots,"eps",width = 6,height = 6,units = "in",dpi = 1200)

  # Benchmark svm Using all HyperCombination supplied by tune.svm
    setRNG::setRNG("L'Ecuyer",101)
    final.svm.model <- lrn.fun(cl = "classif.svm",id = "SVM",par.vals = svm.set,task = Benchmark_Task,resampling = Rdesc_Outer,objectives = Measures,dummy=F,preproc=F,aggr=F,seed = 101)

```

Init the Generalized Linear Model (lr) using : R Stats Package.
```{r Benchmark lr, message=FALSE, warning=FALSE, include=FALSE}
  ## Set Seed
  setRNG::setRNG("L'Ecuyer",101)
  # Benchmark lr
  final.lr.model = lrn.fun(cl = "classif.binomial",id = "LR",par.vals = list(link = "logit" ),task = Benchmark_Task,resampling = Rdesc_Outer,objectives = Measures,dummy=F,preproc=F,aggr=F,seed = 101)
```

Init the Linear Discriminant Analysis (LDA) using: Modern Applied Statistics with S(MASS) Package.
```{r Benchmark LDA, message=FALSE, warning=FALSE, include=FALSE}
  ## Set Seed
  setRNG::setRNG("L'Ecuyer",101)
  # Benchmark lda
  final.lda.model = lrn.fun(cl = "classif.lda",id = "lda",par.vals = list(method = "moment" ),task = Benchmark_Task,resampling = Rdesc_Outer,objectives = Measures,dummy=F,preproc=F,aggr=F,seed = 101)
```


```{r Overall.Perf, message=FALSE, warning=FALSE, include=FALSE}

  Learners.List = list(final.gbm.model,final.lr.model,final.nnet.model,final.rf.model,final.svm.model)
  names(Learners.List) <- c("final_gbm_model","final_lr_model","final_nnet_model","final_rf_model","final_svm_model")
  
  ## Generate Auc Plots
  ## For sperated Roc Plots
  Auc.Plots.List <- lapply(Learners.List,function(x){
    Roc.Plot.Comaprison(Learners = Learners.List,Main.Learner = x,
                        Other.Learners.Color = "#A2AAB3",Main.Learner.Color = "#56B4E9")})
  names(Auc.Plots.List) <- names(Learners.List)
  
  ## For Stacked ROC-Plot
  Roc.Auc.Plot=Roc.Plot.Stacked(Learners.List)

  ## Export AUC-ROC Plots
  for(i in 1:length(Auc.Plots.List)){
    
    ggsave(file.path(PROJHOME, "Outputs","Figures",paste0(names(Auc.Plots.List[i]),"_roc.eps")),plot = Auc.Plots.List[[i]],width = 5,height = 5,dpi = 1200 ,device = "eps",units = "in")
    
  }
  
  ## For Stacked ROC-Plot
  ggsave(file.path(PROJHOME, "Outputs","Figures","Roc_AUC.eps"),plot = Roc.Auc.Plot,width = 5,height = 5,dpi = 1200 ,device = "eps",units = "in")
  
  ## Generate Overall Performace Table
  Overall.Perf.table=dplyr::bind_rows(lapply(Learners.List,function(x){
    
    raw.df = data.frame(t(as.data.frame(x$aggr)))
    
    dplyr::select(raw.df,contains(".test.")) %>%
      `colnames<-`(gsub("\\b\\..*","",colnames(.),fixed = F)) %>%
      dplyr::mutate(.,Stage="Test") %>%
      dplyr::mutate(.,Learner=x$learner.id) -> tst
    
    dplyr::select(raw.df,contains(".train.")) %>%
      `colnames<-`(gsub("\\b\\..*","",colnames(.),fixed = F)) %>%
      dplyr::mutate(.,Stage="Train") %>%
      dplyr::mutate(.,Learner=x$learner.id) -> trn
    
    raw.final=rbind(tst,trn)
    return(raw.final)
    
  }))
  Overall.Perf.table[,1:4]=apply(dplyr::select_if(Overall.Perf.table, is.numeric),2,function(x)round(x,3))
  
  ## Export Overall Performace Table
  write.csv(Overall.Perf.table,file.path(PROJHOME, "Outputs","Tables","Overall.Perf.table.csv"), row.names=F)
```

